{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : CTC Loss\n",
    "from typing import List\n",
    "\n",
    "import cv2\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook lip_keypoint.ipynb to python\n",
      "[NbConvertApp] Writing 9265 bytes to lip_keypoint.py\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert lip_keypoint.ipynb --to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df3 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_landmarks_data3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m df4 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_landmarks_data4.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m df5 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_landmarks_data5.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"face_landmarks_data3.csv\", index_col=0)\n",
    "df4 = pd.read_csv(\"face_landmarks_data4.csv\", index_col=0)\n",
    "df5 = pd.read_csv(\"face_landmarks_data5.csv\", index_col=0)\n",
    "df = pd.concat([df3, df4, df5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path_counts = df['video_path'].value_counts()\n",
    "\n",
    "video_paths_to_keep = video_path_counts[video_path_counts == 3000].index\n",
    "\n",
    "df = df[df['video_path'].isin(video_paths_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = np.mean(df['x'])\n",
    "std_x = np.std(df['x'])\n",
    "mean_y = np.mean(df['y'])\n",
    "std_y = np.std(df['y'])\n",
    "mean_z = np.mean(df['z'])\n",
    "std_z = np.std(df['z'])\n",
    "\n",
    "# df['x'] = (df['x'] - mean_x) / std_x\n",
    "# df['y'] = (df['y'] - mean_y) / std_y\n",
    "# df['z'] = (df['z'] - mean_z) / std_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>visibility</th>\n",
       "      <th>video_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528295</td>\n",
       "      <td>0.712854</td>\n",
       "      <td>-0.031539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data3/s3\\bbaf1s.mpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.543726</td>\n",
       "      <td>0.710494</td>\n",
       "      <td>-0.030296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data3/s3\\bbaf1s.mpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559562</td>\n",
       "      <td>0.715571</td>\n",
       "      <td>-0.022568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data3/s3\\bbaf1s.mpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.570321</td>\n",
       "      <td>0.721982</td>\n",
       "      <td>-0.012750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data3/s3\\bbaf1s.mpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>0.728252</td>\n",
       "      <td>-0.018017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data3/s3\\bbaf1s.mpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame         x         y         z  visibility           video_path\n",
       "0      1  0.528295  0.712854 -0.031539         0.0  data3/s3\\bbaf1s.mpg\n",
       "1      1  0.543726  0.710494 -0.030296         0.0  data3/s3\\bbaf1s.mpg\n",
       "2      1  0.559562  0.715571 -0.022568         0.0  data3/s3\\bbaf1s.mpg\n",
       "3      1  0.570321  0.721982 -0.012750         0.0  data3/s3\\bbaf1s.mpg\n",
       "4      1  0.528245  0.728252 -0.018017         0.0  data3/s3\\bbaf1s.mpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data3/s3\\bbaf1s.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data3/s3\\bbaf2p.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data3/s3\\bbaf3a.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data3/s3\\bbafzn.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data3/s3\\bbal4n.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data5/s5\\swwpzp.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data5/s5\\swwv2n.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data5/s5\\swwv3s.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data5/s5\\swwv4p.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data5/s5\\swwv5a.mpg</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2977 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     frame     x     y     z  visibility\n",
       "video_path                                              \n",
       "data3/s3\\bbaf1s.mpg   3000  3000  3000  3000        3000\n",
       "data3/s3\\bbaf2p.mpg   3000  3000  3000  3000        3000\n",
       "data3/s3\\bbaf3a.mpg   3000  3000  3000  3000        3000\n",
       "data3/s3\\bbafzn.mpg   3000  3000  3000  3000        3000\n",
       "data3/s3\\bbal4n.mpg   3000  3000  3000  3000        3000\n",
       "...                    ...   ...   ...   ...         ...\n",
       "data5/s5\\swwpzp.mpg   3000  3000  3000  3000        3000\n",
       "data5/s5\\swwv2n.mpg   3000  3000  3000  3000        3000\n",
       "data5/s5\\swwv3s.mpg   3000  3000  3000  3000        3000\n",
       "data5/s5\\swwv4p.mpg   3000  3000  3000  3000        3000\n",
       "data5/s5\\swwv5a.mpg   3000  3000  3000  3000        3000\n",
       "\n",
       "[2977 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('video_path').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.copy()\n",
    "chunks = []\n",
    "num_frames_per_chunk = 3000\n",
    "for video_path, group in df_filtered.groupby('video_path'):\n",
    "    num_frames = len(group)\n",
    "    num_chunks = num_frames // num_frames_per_chunk\n",
    "    for i in range(num_chunks):\n",
    "        chunk = group.iloc[i*num_frames_per_chunk:(i+1)*num_frames_per_chunk]\n",
    "        chunk_reshaped = chunk[['x', 'y', 'z']].values.reshape(-1, 75, 40*3)\n",
    "        chunks.append(chunk_reshaped)\n",
    "\n",
    "input_data = np.concatenate(chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2977, 75, 120)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab():\n",
    "    vocab = \"abcdefghijklmnopqrstuvwxyz123456789 \"\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def char_to_int(char):\n",
    "    # shift 1 \n",
    "    vocab = \"abcdefghijklmnopqrstuvwxyz123456789 \"\n",
    "    return vocab.index(char) + 1 if char in vocab else -1\n",
    "\n",
    "def int_to_char(index):\n",
    "    # shift 1 \n",
    "    vocab = \"abcdefghijklmnopqrstuvwxyz123456789 \"\n",
    "    return vocab[index - 1] if 1 <= index <= len(vocab) else ''\n",
    "\n",
    "def load_alignments(path:str) -> List[str]:\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil':\n",
    "            tokens.extend([*line[2]])\n",
    "            tokens.append(' ')\n",
    "    return [char_to_int(token) for token in tokens]\n",
    "\n",
    "all_alignments = []\n",
    "for video_path in df['video_path'].unique():\n",
    "    datapath = video_path.split('/')[0]\n",
    "    speaker_path = video_path.split('/')[-1].split('\\\\')[0]\n",
    "    vid_path = video_path.split('/')[-1].split('\\\\')[-1].split('.')[0]\n",
    "    \n",
    "    alignment_path = os.path.join(f'{datapath}','align',f'{vid_path}.align')\n",
    "    alignments = load_alignments(alignment_path) \n",
    "    all_alignments.append(alignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2977"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = df['video_path'].iloc[0]\n",
    "# datapath = video_path.split('/')\n",
    "# speakert_path = video_path.split('/')[-1].split('\\\\')[0]\n",
    "# vid_path = video_path.split('/')[-1].split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (2977, 75, 120)\n",
      "Number of label sequences: 2977\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_data = [np.array(label) for label in all_alignments if label]\n",
    "# Example of shaping your input data and label data for model training\n",
    "#input_data = np.stack(chunks)  # Ensure that chunks are correctly reshaped and stacked\n",
    "\n",
    "# Check shapes (important for debugging)\n",
    "print(\"Input data shape:\", input_data.shape)\n",
    "print(\"Number of label sequences:\", len(label_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2977, 75, 120)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_data, label_data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipReadingRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LipReadingRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.bilstm = nn.LSTM(hidden_size, hidden_size, num_layers=3, batch_first=True, bidirectional=True, dropout=0.3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.input_layer:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "        \n",
    "        for name, param in self.bilstm.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "                \n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)  \n",
    "        h0 = torch.zeros(6, x.size(0), self.hidden_size).to(x.device)  # 6 for 3 layers bidirectional\n",
    "        c0 = torch.zeros(6, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.bilstm(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)  \n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  9, 14, 36, 23,  8,  9, 20,  5, 36,  1, 20, 36, 19, 36, 14,  9, 14,\n",
       "          5, 36, 19, 15, 15, 14, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36, 23,  8,  9, 20,  5, 36, 23,  9, 20,  8, 36, 24,\n",
       "         36,  5,  9,  7,  8, 20, 36, 14, 15, 23, 36,  0,  0],\n",
       "        [19,  5, 20, 36,  7, 18,  5,  5, 14, 36,  1, 20, 36,  2, 36, 14,  9, 14,\n",
       "          5, 36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [19,  5, 20, 36,  7, 18,  5,  5, 14, 36,  9, 14, 36,  2, 36, 19,  9, 24,\n",
       "         36,  1,  7,  1,  9, 14, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [12,  1, 25, 36, 23,  8,  9, 20,  5, 36, 23,  9, 20,  8, 36, 26, 36, 19,\n",
       "          5, 22,  5, 14, 36, 16, 12,  5,  1, 19,  5, 36,  0],\n",
       "        [12,  1, 25, 36,  7, 18,  5,  5, 14, 36,  1, 20, 36,  6, 36, 20, 23, 15,\n",
       "         36, 19, 15, 15, 14, 36,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [12,  1, 25, 36,  2, 12, 21,  5, 36,  9, 14, 36, 24, 36,  6, 15, 21, 18,\n",
       "         36,  1,  7,  1,  9, 14, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [12,  1, 25, 36,  2, 12, 21,  5, 36, 23,  9, 20,  8, 36, 18, 36, 26,  5,\n",
       "         18, 15, 36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  9, 14, 36, 23,  8,  9, 20,  5, 36,  2, 25, 36, 20, 36,  6,  9, 22,\n",
       "          5, 36, 19, 15, 15, 14, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36,  7, 18,  5,  5, 14, 36,  2, 25, 36, 17, 36, 14,\n",
       "          9, 14,  5, 36,  1,  7,  1,  9, 14, 36,  0,  0,  0],\n",
       "        [19,  5, 20, 36, 23,  8,  9, 20,  5, 36, 23,  9, 20,  8, 36, 19, 16, 36,\n",
       "          2, 36, 14,  9, 14,  5, 36, 14, 15, 23, 36,  0,  0],\n",
       "        [19,  5, 20, 36,  7, 18,  5,  5, 14, 36,  1, 20, 36, 15, 36, 19,  5, 22,\n",
       "          5, 14, 36, 19, 15, 15, 14, 36,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36,  2, 12, 21,  5, 36,  2, 25, 36,  9, 36, 19,  9,\n",
       "         24, 36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36,  2, 12, 21,  5, 36, 23,  9, 20,  8, 36, 16, 36,\n",
       "         19,  5, 22,  5, 14, 36,  1,  7,  1,  9, 14, 36,  0],\n",
       "        [19,  5, 20, 36,  2, 12, 21,  5, 36, 23,  9, 20,  8, 36,  8, 36, 20,  8,\n",
       "         18,  5,  5, 36, 19, 15, 15, 14, 36,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36,  7, 18,  5,  5, 14, 36, 23,  9, 20,  8, 36, 11,\n",
       "         36,  5,  9,  7,  8, 20, 36,  1,  7,  1,  9, 14, 36],\n",
       "        [19,  5, 20, 36, 18,  5,  4, 36, 23,  9, 20,  8, 36, 15, 36,  6,  9, 22,\n",
       "          5, 36, 19, 15, 15, 14, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  9, 14, 36, 18,  5,  4, 36,  9, 14, 36, 26, 36, 19,  9, 24, 36,  1,\n",
       "          7,  1,  9, 14, 36,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36,  2, 12, 21,  5, 36,  1, 20, 36, 21, 36, 14,  9,\n",
       "         14,  5, 36, 19, 15, 15, 14, 36,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36,  2, 12, 21,  5, 36,  1, 20, 36, 19, 16, 36, 22,\n",
       "         36, 15, 14,  5, 36, 19, 15, 15, 14, 36,  0,  0,  0],\n",
       "        [12,  1, 25, 36,  2, 12, 21,  5, 36,  1, 20, 36, 16, 36, 14,  9, 14,  5,\n",
       "         36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36, 18,  5,  4, 36,  1, 20, 36,  9, 36, 19,  5, 22,\n",
       "          5, 14, 36, 16, 12,  5,  1, 19,  5, 36,  0,  0,  0],\n",
       "        [19,  5, 20, 36,  7, 18,  5,  5, 14, 36, 23,  9, 20,  8, 36,  3, 36, 19,\n",
       "          9, 24, 36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [12,  1, 25, 36, 18,  5,  4, 36,  1, 20, 36, 18, 36, 26,  5, 18, 15, 36,\n",
       "         16, 12,  5,  1, 19,  5, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [12,  1, 25, 36,  7, 18,  5,  5, 14, 36,  9, 14, 36, 18, 36, 19,  9, 24,\n",
       "         36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  9, 14, 36,  7, 18,  5,  5, 14, 36,  9, 14, 36,  1, 36, 15, 14,  5,\n",
       "         36,  1,  7,  1,  9, 14, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [12,  1, 25, 36, 23,  8,  9, 20,  5, 36, 23,  9, 20,  8, 36, 13, 36, 15,\n",
       "         14,  5, 36,  1,  7,  1,  9, 14, 36,  0,  0,  0,  0],\n",
       "        [19,  5, 20, 36, 18,  5,  4, 36,  9, 14, 36,  1, 36,  6, 15, 21, 18, 36,\n",
       "          1,  7,  1,  9, 14, 36,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [16, 12,  1,  3,  5, 36, 18,  5,  4, 36, 23,  9, 20,  8, 36, 10, 36, 19,\n",
       "          9, 24, 36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [19,  5, 20, 36,  7, 18,  5,  5, 14, 36,  9, 14, 36,  8, 36, 19,  5, 22,\n",
       "          5, 14, 36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0],\n",
       "        [19,  5, 20, 36,  2, 12, 21,  5, 36,  9, 14, 36, 20, 36, 26,  5, 18, 15,\n",
       "         36, 14, 15, 23, 36,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [19,  5, 20, 36,  2, 12, 21,  5, 36, 23,  9, 20,  8, 36,  8, 36,  6, 15,\n",
       "         21, 18, 36, 16, 12,  5,  1, 19,  5, 36,  0,  0,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "first_input, _, labels, _ = first_batch \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 34]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 34]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 33]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 35]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 34]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 28]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 32]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 35]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 34]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 36]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 34]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 28]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 30]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 31]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 35]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 35]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 32, 37]) torch.Size([32, 29]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([75, 13, 37]) torch.Size([13, 31]) torch.Size([13]) torch.Size([13])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input_lengths must be of size batch_size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 47>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCTCLoss(blank\u001b[38;5;241m=\u001b[39mnum_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, zero_infinity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader, criterion, optimizer, device, num_epochs)\u001b[0m\n\u001b[0;32m     27\u001b[0m         inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     28\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m---> 29\u001b[0m         val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m         total_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m val_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     31\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m total_val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1756\u001b[0m, in \u001b[0;36mCTCLoss.forward\u001b[1;34m(self, log_probs, targets, input_lengths, target_lengths)\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_infinity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2628\u001b[0m, in \u001b[0;36mctc_loss\u001b[1;34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[0m\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(log_probs, targets, input_lengths, target_lengths):\n\u001b[0;32m   2622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2623\u001b[0m         ctc_loss,\n\u001b[0;32m   2624\u001b[0m         (log_probs, targets, input_lengths, target_lengths),\n\u001b[0;32m   2625\u001b[0m         log_probs, targets, input_lengths, target_lengths,\n\u001b[0;32m   2626\u001b[0m         blank\u001b[38;5;241m=\u001b[39mblank, reduction\u001b[38;5;241m=\u001b[39mreduction, zero_infinity\u001b[38;5;241m=\u001b[39mzero_infinity\n\u001b[0;32m   2627\u001b[0m     )\n\u001b[1;32m-> 2628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctc_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_infinity\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input_lengths must be of size batch_size"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, device, num_epochs=100):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, input_lengths, targets, target_lengths) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "            outputs = F.log_softmax(outputs, dim=2)\n",
    "            print(outputs.shape, targets.shape, input_lengths.shape, target_lengths.shape)\n",
    "            loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, input_lengths, targets, target_lengths in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "                total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(test_loader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {avg_loss}, Validation Loss: {avg_val_loss}')\n",
    "\n",
    "\n",
    "vocab = create_vocab()\n",
    "vocab_len = len(vocab)\n",
    "num_classes = vocab_len + 1 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = LipReadingRNN(input_size=120, hidden_size=256, num_classes=num_classes).to(device)\n",
    "criterion = nn.CTCLoss(blank=num_classes - 1, zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, device, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input sample for inference: torch.Size([32, 75, 120])\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(iter(test_loader))\n",
    "    \n",
    "first_input, _, labels, _ = first_batch \n",
    "\n",
    "print(\"Shape of the input sample for inference:\", first_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75, 120])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    log_probs = model(first_input.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75, 32, 37])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75, 37])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[:,25,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'place white in p three please '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(int_to_char(idx) for idx in labels[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'set    bre e     it         s     sine            sn          on           '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices = [np.argmax(log_prob) for log_prob in torch.exp(log_probs[:,25].cpu())]\n",
    "''.join(int_to_char(idx) for idx in max_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded sequence indices: [tensor(12, device='cuda:0'), tensor(1, device='cuda:0'), tensor(25, device='cuda:0'), tensor(36, device='cuda:0'), tensor(18, device='cuda:0'), tensor(5, device='cuda:0'), tensor(36, device='cuda:0'), tensor(5, device='cuda:0'), tensor(36, device='cuda:0'), tensor(9, device='cuda:0'), tensor(20, device='cuda:0'), tensor(36, device='cuda:0'), tensor(5, device='cuda:0'), tensor(36, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "\n",
    "def greedy_decoder(ctc_output, blank_label=0):\n",
    "    probabilities = torch.exp(ctc_output)\n",
    "    _, max_indices = torch.max(probabilities, 2)\n",
    "    indices = max_indices.squeeze(1)  \n",
    "    decoded_sequence = [index for index, group in itertools.groupby(indices) if index != blank_label]\n",
    "    return decoded_sequence\n",
    "\n",
    "decoded_sequence = greedy_decoder(log_probs)\n",
    "print(\"Decoded sequence indices:\", decoded_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lay re e it e '"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(int_to_char(idx) for idx in decoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
