{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:23<00:00, 83.33s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:23<00:00, 83.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize dlib's face detector and landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('data_kaggle/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def get_landmarks(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 1)\n",
    "    if len(rects) > 0:\n",
    "        shape = predictor(gray, rects[0])\n",
    "        landmarks = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        return landmarks\n",
    "    return None\n",
    "\n",
    "def pad_sequence(sequence, max_length):\n",
    "    while len(sequence) < max_length:\n",
    "        sequence.append(sequence[-1])\n",
    "    return sequence\n",
    "\n",
    "def load_and_preprocess_data(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_length = 0\n",
    "    i = 1\n",
    "    # First pass to determine the maximum sequence length\n",
    "    for person in tqdm(os.listdir(dataset_path)):\n",
    "        person_path = os.path.join(dataset_path, person)\n",
    "        words_path = os.path.join(person_path, 'words')\n",
    "        if not os.path.isdir(words_path):\n",
    "            continue\n",
    "        print(i)\n",
    "        i += 1\n",
    "        for word in os.listdir(words_path):\n",
    "            word_path = os.path.join(words_path, word)\n",
    "            for example in os.listdir(word_path):\n",
    "                example_path = os.path.join(word_path, example)\n",
    "                landmarks_sequence = []\n",
    "                for frame_file in os.listdir(example_path):\n",
    "                    if frame_file.startswith('color'):\n",
    "                        frame_path = os.path.join(example_path, frame_file)\n",
    "                        image = cv2.imread(frame_path)\n",
    "                        landmarks = get_landmarks(image)\n",
    "                        if landmarks is not None:\n",
    "                            landmarks_sequence.append(landmarks)\n",
    "                if landmarks_sequence:\n",
    "                    max_length = max(max_length, len(landmarks_sequence))\n",
    "\n",
    "    i = 1\n",
    "    # Second pass to load and pad the data\n",
    "    for person in tqdm(os.listdir(dataset_path)):\n",
    "        print(i)\n",
    "        i += 1\n",
    "        person_path = os.path.join(dataset_path, person)\n",
    "        words_path = os.path.join(person_path, 'words')\n",
    "        if not os.path.isdir(words_path):\n",
    "            continue\n",
    "        for word in os.listdir(words_path):\n",
    "            word_path = os.path.join(words_path, word)\n",
    "            for example in os.listdir(word_path):\n",
    "                example_path = os.path.join(word_path, example)\n",
    "                landmarks_sequence = []\n",
    "                for frame_file in os.listdir(example_path):\n",
    "                    if frame_file.startswith('color'):\n",
    "                        frame_path = os.path.join(example_path, frame_file)\n",
    "                        image = cv2.imread(frame_path)\n",
    "                        landmarks = get_landmarks(image)\n",
    "                        if landmarks is not None:\n",
    "                            landmarks_sequence.append(landmarks)\n",
    "                if landmarks_sequence:\n",
    "                    padded_sequence = pad_sequence(landmarks_sequence, max_length)\n",
    "                    data.append(padded_sequence)\n",
    "                    labels.append(word)\n",
    "        \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "dataset_path = 'data_kaggle/dataset/dataset/'\n",
    "data, labels = load_and_preprocess_data(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lip_landmarks(data):\n",
    "    lip_data = data[:, :, 48:68, :]\n",
    "    return lip_data\n",
    "\n",
    "lip_data = extract_lip_landmarks(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_landmarks(landmarks):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    outer_lip = landmarks[48:60]\n",
    "    inner_lip = landmarks[60:68]\n",
    "    \n",
    "    # Plot each region\n",
    "\n",
    "    plt.plot(outer_lip[:, 0], outer_lip[:, 1], c='blue')\n",
    "    plt.plot(inner_lip[:, 0], inner_lip[:, 1], c='blue')\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Landmarks for data[0][0]')\n",
    "    plt.xlabel('X coordinates')\n",
    "    plt.ylabel('Y coordinates')\n",
    "    plt.show()\n",
    "\n",
    "example_landmarks = data[0][0]\n",
    "plot_landmarks(example_landmarks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data.npy', data)\n",
    "# np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data.npy')\n",
    "labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'e', 'g', 'h', 'i', 'l', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
     ]
    }
   ],
   "source": [
    "int_to_word = {\n",
    "    1: \"begin\",\n",
    "    2: \"choose\",\n",
    "    3: \"connection\",\n",
    "    4: \"navigation\",\n",
    "    5: \"next\",\n",
    "    6: \"previous\",\n",
    "    7: \"start\",\n",
    "    8: \"stop\",\n",
    "    9: \"hello\",\n",
    "    10: \"web\"\n",
    "}\n",
    "\n",
    "vocab = set()\n",
    "for word in int_to_word.values():\n",
    "    for char in word:\n",
    "        vocab.add(char)\n",
    "\n",
    "vocab = sorted(list(vocab))\n",
    "\n",
    "print(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2char = {i: char for i, char in enumerate(vocab)}\n",
    "char2int = {char: i for i, char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_int = np.array(labels).astype(int)\n",
    "labels_ = np.array([int_to_word[label] for label in labels_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tensor = []\n",
    "for label in labels_:\n",
    "    label_indices = [char2int[char] for char in label]\n",
    "    labels_tensor.append(torch.tensor(label_indices, dtype=torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_label = len(char2int)\n",
    "char2int['blank'] = blank_label\n",
    "int2char = {i: char for char, i in char2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tensor = torch.nn.utils.rnn.pad_sequence(labels_tensor, batch_first=True, padding_value=blank_label)\n",
    "target_lengths = torch.tensor([len(label) for label in labels], dtype=torch.int)\n",
    "data_tensor = torch.tensor(data, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 3060\n",
      "Epoch [1/200], Training Loss: 3.7088, Validation Loss: 3.0234\n",
      "Epoch [2/200], Training Loss: 2.9954, Validation Loss: 2.9023\n",
      "Epoch [3/200], Training Loss: 2.8394, Validation Loss: 2.7155\n",
      "Epoch [4/200], Training Loss: 2.6872, Validation Loss: 2.6043\n",
      "Epoch [5/200], Training Loss: 2.5798, Validation Loss: 2.5297\n",
      "Epoch [6/200], Training Loss: 2.5299, Validation Loss: 2.4880\n",
      "Epoch [7/200], Training Loss: 2.4677, Validation Loss: 2.4359\n",
      "Epoch [8/200], Training Loss: 2.4387, Validation Loss: 2.3726\n",
      "Epoch [9/200], Training Loss: 2.4157, Validation Loss: 2.3970\n",
      "Epoch [10/200], Training Loss: 2.4110, Validation Loss: 2.3791\n",
      "Epoch [11/200], Training Loss: 2.3747, Validation Loss: 2.3294\n",
      "Epoch [12/200], Training Loss: 2.3631, Validation Loss: 2.3044\n",
      "Epoch [13/200], Training Loss: 2.3506, Validation Loss: 2.3214\n",
      "Epoch [14/200], Training Loss: 2.3419, Validation Loss: 2.3039\n",
      "Epoch [15/200], Training Loss: 2.3348, Validation Loss: 2.3290\n",
      "Epoch [16/200], Training Loss: 2.3214, Validation Loss: 2.2833\n",
      "Epoch [17/200], Training Loss: 2.3056, Validation Loss: 2.2145\n",
      "Epoch [18/200], Training Loss: 2.2919, Validation Loss: 2.2361\n",
      "Epoch [19/200], Training Loss: 2.2605, Validation Loss: 2.1861\n",
      "Epoch [20/200], Training Loss: 2.2117, Validation Loss: 2.1103\n",
      "Epoch [21/200], Training Loss: 2.1483, Validation Loss: 2.0358\n",
      "Epoch [22/200], Training Loss: 2.0909, Validation Loss: 1.9369\n",
      "Epoch [23/200], Training Loss: 1.9880, Validation Loss: 1.8947\n",
      "Epoch [24/200], Training Loss: 1.9186, Validation Loss: 1.7710\n",
      "Epoch [25/200], Training Loss: 1.8658, Validation Loss: 1.7554\n",
      "Epoch [26/200], Training Loss: 1.7994, Validation Loss: 1.6828\n",
      "Epoch [27/200], Training Loss: 1.7023, Validation Loss: 1.5940\n",
      "Epoch [28/200], Training Loss: 1.6182, Validation Loss: 1.5302\n",
      "Epoch [29/200], Training Loss: 1.6230, Validation Loss: 1.5744\n",
      "Epoch [30/200], Training Loss: 1.5137, Validation Loss: 1.5153\n",
      "Epoch [31/200], Training Loss: 1.4406, Validation Loss: 1.4831\n",
      "Epoch [32/200], Training Loss: 1.4531, Validation Loss: 1.4816\n",
      "Epoch [33/200], Training Loss: 1.3580, Validation Loss: 1.3625\n",
      "Epoch [34/200], Training Loss: 1.2477, Validation Loss: 1.4604\n",
      "Epoch [35/200], Training Loss: 1.2212, Validation Loss: 1.3588\n",
      "Epoch [36/200], Training Loss: 1.1091, Validation Loss: 1.0356\n",
      "Epoch [37/200], Training Loss: 1.0453, Validation Loss: 1.3318\n",
      "Epoch [38/200], Training Loss: 1.0453, Validation Loss: 1.1727\n",
      "Epoch [39/200], Training Loss: 0.8806, Validation Loss: 0.9148\n",
      "Epoch [40/200], Training Loss: 0.7404, Validation Loss: 0.9009\n",
      "Epoch [41/200], Training Loss: 0.6555, Validation Loss: 0.9247\n",
      "Epoch [42/200], Training Loss: 0.7265, Validation Loss: 1.1637\n",
      "Epoch [43/200], Training Loss: 0.6090, Validation Loss: 0.8449\n",
      "Epoch [44/200], Training Loss: 0.5820, Validation Loss: 1.3360\n",
      "Epoch [45/200], Training Loss: 0.5128, Validation Loss: 0.8671\n",
      "Epoch [46/200], Training Loss: 0.4654, Validation Loss: 0.7142\n",
      "Epoch [47/200], Training Loss: 0.3543, Validation Loss: 0.7972\n",
      "Epoch [48/200], Training Loss: 0.4463, Validation Loss: 0.8676\n",
      "Epoch [49/200], Training Loss: 0.4528, Validation Loss: 0.6621\n",
      "Epoch [50/200], Training Loss: 0.3276, Validation Loss: 0.6320\n",
      "Epoch [51/200], Training Loss: 0.2856, Validation Loss: 0.6698\n",
      "Epoch [52/200], Training Loss: 0.2620, Validation Loss: 0.6390\n",
      "Epoch [53/200], Training Loss: 0.2693, Validation Loss: 0.8547\n",
      "Epoch [54/200], Training Loss: 0.2793, Validation Loss: 0.7717\n",
      "Epoch [55/200], Training Loss: 0.2783, Validation Loss: 0.7333\n",
      "Epoch [56/200], Training Loss: 0.2645, Validation Loss: 0.7729\n",
      "Epoch [57/200], Training Loss: 0.1665, Validation Loss: 0.8011\n",
      "Epoch [58/200], Training Loss: 0.1020, Validation Loss: 0.5358\n",
      "Epoch [59/200], Training Loss: 0.0708, Validation Loss: 0.5230\n",
      "Epoch [60/200], Training Loss: 0.0701, Validation Loss: 0.5653\n",
      "Epoch [61/200], Training Loss: 0.2380, Validation Loss: 1.2970\n",
      "Epoch [62/200], Training Loss: 0.5956, Validation Loss: 0.7223\n",
      "Epoch [63/200], Training Loss: 0.1913, Validation Loss: 0.6419\n",
      "Epoch [64/200], Training Loss: 0.1143, Validation Loss: 0.5365\n",
      "Epoch [65/200], Training Loss: 0.0837, Validation Loss: 0.5886\n",
      "Epoch [66/200], Training Loss: 0.0870, Validation Loss: 0.6203\n",
      "Epoch [67/200], Training Loss: 0.0630, Validation Loss: 0.4999\n",
      "Epoch [68/200], Training Loss: 0.0369, Validation Loss: 0.5153\n",
      "Epoch [69/200], Training Loss: 0.0380, Validation Loss: 0.4950\n",
      "Epoch [70/200], Training Loss: 0.0842, Validation Loss: 0.4997\n",
      "Epoch [71/200], Training Loss: 0.0611, Validation Loss: 1.0925\n",
      "Epoch [72/200], Training Loss: 0.1934, Validation Loss: 0.8186\n",
      "Epoch [73/200], Training Loss: 0.3210, Validation Loss: 0.6946\n",
      "Epoch [74/200], Training Loss: 0.1450, Validation Loss: 0.8970\n",
      "Epoch [75/200], Training Loss: 0.1084, Validation Loss: 0.5586\n",
      "Epoch [76/200], Training Loss: 0.0751, Validation Loss: 0.6130\n",
      "Epoch [77/200], Training Loss: 0.1403, Validation Loss: 2.1407\n",
      "Epoch [78/200], Training Loss: 0.7404, Validation Loss: 0.6980\n",
      "Epoch [79/200], Training Loss: 0.1899, Validation Loss: 0.6005\n",
      "Epoch [80/200], Training Loss: 0.0533, Validation Loss: 0.4659\n",
      "Epoch [81/200], Training Loss: 0.0309, Validation Loss: 0.5099\n",
      "Epoch [82/200], Training Loss: 0.0178, Validation Loss: 0.4950\n",
      "Epoch [83/200], Training Loss: 0.0142, Validation Loss: 0.4937\n",
      "Epoch [84/200], Training Loss: 0.0121, Validation Loss: 0.5092\n",
      "Epoch [85/200], Training Loss: 0.0105, Validation Loss: 0.5017\n",
      "Epoch [86/200], Training Loss: 0.0097, Validation Loss: 0.5259\n",
      "Epoch [87/200], Training Loss: 0.0089, Validation Loss: 0.5246\n",
      "Epoch [88/200], Training Loss: 0.0083, Validation Loss: 0.5297\n",
      "Epoch [89/200], Training Loss: 0.0073, Validation Loss: 0.5260\n",
      "Epoch [90/200], Training Loss: 0.0070, Validation Loss: 0.5342\n",
      "Epoch [91/200], Training Loss: 0.0066, Validation Loss: 0.5279\n",
      "Epoch [92/200], Training Loss: 0.0062, Validation Loss: 0.5442\n",
      "Epoch [93/200], Training Loss: 0.0057, Validation Loss: 0.5321\n",
      "Epoch [94/200], Training Loss: 0.0054, Validation Loss: 0.5432\n",
      "Epoch [95/200], Training Loss: 0.0053, Validation Loss: 0.5553\n",
      "Epoch [96/200], Training Loss: 0.0050, Validation Loss: 0.5509\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 73>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m2\u001b[39m), labels, input_lengths, target_lengths)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 89\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     92\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "class LipReadingRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LipReadingRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.bilstm = nn.LSTM(hidden_size, hidden_size, num_layers=3, batch_first=True, bidirectional=True, dropout=0.3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.input_layer:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "        \n",
    "        for name, param in self.bilstm.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "                \n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)  \n",
    "        h0 = torch.zeros(6, x.size(0), self.hidden_size).to(x.device)  \n",
    "        c0 = torch.zeros(6, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.bilstm(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)  \n",
    "        \n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = data_tensor.shape[2] * data_tensor.shape[3]\n",
    "hidden_size = 512\n",
    "num_classes = len(char2int) \n",
    "model = LipReadingRNN(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CTCLoss(blank=blank_label, reduction='mean', zero_infinity=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=200, gamma=0.1)\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for sequences, labels in train_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        sequences = sequences.view(sequences.size(0), sequences.size(1), -1).to(device) # (batch_size, seq_len, input_size)\n",
    "        \n",
    "        outputs = model(sequences)\n",
    "        \n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "        input_lengths = torch.full((sequences.size(0),), sequences.size(1), dtype=torch.long).to(device)\n",
    "        target_lengths = torch.tensor([label[label != blank_label].size(0) for label in labels], dtype=torch.long).to(device)\n",
    "        loss = criterion(outputs.log_softmax(2), labels, input_lengths, target_lengths).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            sequences = sequences.view(sequences.size(0), sequences.size(1), -1).to(device) # (batch_size, seq_len, input_size)\n",
    "\n",
    "            outputs = model(sequences)\n",
    "\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "            input_lengths = torch.full((sequences.size(0),), sequences.size(1), dtype=torch.long).to(device)\n",
    "            target_lengths = torch.tensor([label[label != blank_label].size(0) for label in labels], dtype=torch.long).to(device)\n",
    "            loss = criterion(outputs.log_softmax(2), labels, input_lengths, target_lengths).to(device)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(test_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CER: 0.1054\n",
      "Final WER: 0.1067\n",
      "Character Accuracy: 0.8946\n",
      "Word Accuracy: 0.8933\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "def calculate_wer(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculate the Word Error Rate (WER).\n",
    "    - reference: The ground truth string.\n",
    "    - hypothesis: The predicted string.\n",
    "    Returns the WER as a float.\n",
    "    \"\"\"\n",
    "    return jiwer.wer(reference, hypothesis)\n",
    "\n",
    "def calculate_cer(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculate the Character Error Rate (CER).\n",
    "    - reference: The ground truth string.\n",
    "    - hypothesis: The predicted string.\n",
    "    Returns the CER as a float.\n",
    "    \"\"\"\n",
    "    return jiwer.cer(reference, hypothesis)\n",
    "\n",
    "def ctc_greedy_decoder(output, int2char, blank_label):\n",
    "    \"\"\"\n",
    "    Decodes the output of the network using a greedy approach.\n",
    "    - output: The raw output from the network.\n",
    "    - int2char: A dictionary mapping indices to characters.\n",
    "    - blank_label: The index of the blank label.\n",
    "    Returns a list of decoded words.\n",
    "    \"\"\"\n",
    "    decoded_words = []\n",
    "    for batch in output:\n",
    "        word = []\n",
    "        prev_char = None\n",
    "        for i in batch:\n",
    "            char_idx = i.item()\n",
    "            if char_idx != blank_label and (prev_char is None or char_idx != prev_char):\n",
    "                word.append(int2char[char_idx])\n",
    "            prev_char = char_idx\n",
    "        decoded_words.append(''.join(word))\n",
    "    return decoded_words\n",
    "\n",
    "# Ensure the blank label is mapped to a space character if needed\n",
    "# int2char[blank_label] = ' '\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_val_loss = 0\n",
    "    all_golden_words = []\n",
    "    all_predicted_words = []\n",
    "    for sequences, labels in test_loader:\n",
    "        sequences = sequences.view(sequences.size(0), sequences.size(1), -1)  # Flatten the input dimensions\n",
    "        \n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(sequences)\n",
    "        \n",
    "        max_indices = torch.argmax(outputs, dim=2)\n",
    "        \n",
    "        predicted_words = ctc_greedy_decoder(max_indices, int2char, blank_label)\n",
    "        \n",
    "        golden_words = []\n",
    "        for label in labels:\n",
    "            word = []\n",
    "            for i in label:\n",
    "                if i.item() != blank_label:  # Ignore the padding (blank) label\n",
    "                    word.append(int2char[i.item()])\n",
    "            golden_words.append(''.join(word))\n",
    "        \n",
    "        all_golden_words.extend(golden_words)\n",
    "        all_predicted_words.extend(predicted_words)\n",
    "\n",
    "total_cer = sum(calculate_cer(g, p) for g, p in zip(all_golden_words, all_predicted_words)) / len(all_golden_words)\n",
    "total_wer = sum(calculate_wer(g, p) for g, p in zip(all_golden_words, all_predicted_words)) / len(all_golden_words)\n",
    "\n",
    "character_accuracy = 1 - total_cer\n",
    "word_accuracy = sum(1 for g, p in zip(all_golden_words, all_predicted_words) if g == p) / len(all_golden_words)\n",
    "\n",
    "print(f'Final CER: {total_cer:.4f}')\n",
    "print(f'Final WER: {total_wer:.4f}')\n",
    "print(f'Character Accuracy: {character_accuracy:.4f}')\n",
    "print(f'Word Accuracy: {word_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
